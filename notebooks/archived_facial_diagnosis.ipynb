{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87mb2Wqx5CE4"
   },
   "source": [
    "# 0. Get Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msYLITQ5EHij"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import dlib\n",
    "import cv2\n",
    "from os import listdir\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ro8qtCUT4KMN",
    "outputId": "83c85529-0cf2-4a13-8f77-e3a4c47df739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AP5tqi7cUz45"
   },
   "outputs": [],
   "source": [
    "file_dir = './drive/My Drive/oculoplastics_diagnosis/'\n",
    "data_dir = './drive/My Drive/oculoplastics_diagnosis/data/'\n",
    "img_dir = './drive/My Drive/oculoplastics_diagnosis/data/processed/'\n",
    "img_dir_normal = './drive/My Drive/oculoplastics_diagnosis/data/processed/normal/'\n",
    "img_dir_thyroid = './drive/My Drive/oculoplastics_diagnosis/data/processed/normal/thyroid_eye_disease/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "of3MBD3JU0Em"
   },
   "outputs": [],
   "source": [
    "def display_one(a, title = \"Original\"):\n",
    "    plt.imshow(a), plt.title(title)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vd0dddK5NCb"
   },
   "source": [
    "# 1. Cleaning / Cropping & De-identify Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVwtZ6MZ5R4i"
   },
   "outputs": [],
   "source": [
    "def get_random_string(length):\n",
    "    letters = list(string.ascii_lowercase)\n",
    "    result_str = ''.join(random.choice(letters) for i in range(length))\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23HbhFwY11MK"
   },
   "outputs": [],
   "source": [
    "# Predictor file path info\n",
    "predictor_path = file_dir + 'shape_predictor_68_face_landmarks.dat'\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Define text info\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "fontColor = (255, 255, 255)\n",
    "lineType = 2\n",
    "\n",
    "def predict_landmarks(filepath, predictor):\n",
    "    \"\"\"\n",
    "    Predicting the landmarks given a image filepath and a predictor object\n",
    "    nput:\n",
    "        - filepath       : filepath to the image\n",
    "        - predictor      : predictor object\n",
    "    return:\n",
    "        - image          : output image\n",
    "        - shape          : list of landmark locations\n",
    "    \"\"\"\n",
    "\n",
    "    # load the input image, resize it, and convert it to grayscale\n",
    "    image = cv2.imread(filepath)\n",
    "    # image = imutils.resize(image, width = 250)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    rects = face_detector(gray, 1)\n",
    "    if len(rects) == 0:\n",
    "        rects = dlib.rectangles()\n",
    "        h, w = image.shape[0], image.shape[1]\n",
    "        rec = dlib.rectangle(0, 0, w, h)\n",
    "        rects.append(rec)\n",
    "\n",
    "    shape = 0\n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        shape = shape[36:48, :]\n",
    "\n",
    "        # loop over the (x, y)-coordinates for the facial landmarks\n",
    "        # and draw them on the image\n",
    "        # for (x, y) in shape:\n",
    "        #     cv2.circle(image, (x, y), 50, (0, 0, 255), -1)\n",
    "    # return cv2.cvtColor(image, cv2.COLOR_BGR2RGB), shape\n",
    "    return image, shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEa8le2DePJb"
   },
   "source": [
    "- If there are existing images, load their info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zX6jp7jJu4Ae",
    "outputId": "00b5a9ee-f8c8-409e-dec0-079380aad802"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loading_success = False\n",
    "try:\n",
    "    old_img_info_df = pd.read_csv(file_dir + 'data/img_info_df.csv')\n",
    "    if old_img_info_df.shape[0] > 0:\n",
    "        loading_success = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "old_img_info_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rRxSoFLf4K4m",
    "outputId": "dc9a5feb-1bc8-4440-cccc-3e5e979c306f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [40:25<00:00, 12.07s/it]\n"
     ]
    }
   ],
   "source": [
    "img_info_dic = []\n",
    "error_img = []\n",
    "all_key_set = set([])\n",
    "# group_name = 'normal'\n",
    "\n",
    "def clean_group(group_name):\n",
    "    count = 0\n",
    "    for f in tqdm(listdir(file_dir + 'data/raw/' + group_name + '/')):\n",
    "        if '.JPG' not in f:\n",
    "            continue\n",
    "        count += 1\n",
    "        # if count < 91 or count > 100:\n",
    "        #     continue\n",
    "        output, shape = predict_landmarks(file_dir + 'data/raw/' + group_name + '/' + f, predictor)\n",
    "        new_key = get_random_string(20)\n",
    "        while new_key in all_key_set:\n",
    "            new_key = get_random_string(20)\n",
    "        all_key_set.add(new_key)\n",
    "        new_name = group_name + '_' + new_key + '.JPG'\n",
    "        tmp_dic = {}\n",
    "        tmp_dic['original_name'] = f\n",
    "        tmp_dic['new_name'] = new_name\n",
    "        tmp_dic['group'] = group_name\n",
    "\n",
    "        # Cropping\n",
    "        inter_w = shape[6][0] - shape[3][0]\n",
    "        left = int(shape[0][0] - inter_w / 2)\n",
    "        right = int(shape[9][0] + inter_w / 2)\n",
    "        up = min(shape[:, 1])\n",
    "        down = max(shape[:, 1])\n",
    "        inter_h = down - up\n",
    "        up = up - inter_h\n",
    "        down = down + inter_h\n",
    "        output = output[up: down, left: right]\n",
    "        shape = shape - np.array([left, up])\n",
    "        tmp_dic['landmark'] = [tuple(i) for i in shape]\n",
    "\n",
    "        # Saving\n",
    "        if 0 in output.shape:\n",
    "            error_img.append(tmp_dic)\n",
    "            continue\n",
    "        img_info_dic.append(tmp_dic)\n",
    "        cv2.imwrite(file_dir + 'data/processed/' + group_name + '/' + new_name, output)\n",
    "        # for (x, y) in shape:\n",
    "        #     cv2.circle(output, (x, y), 50, (0, 0, 255), -1)\n",
    "        # imgplot = plt.imshow(output)\n",
    "        # plt.show()\n",
    "        # if count == 5:\n",
    "        #     break\n",
    "\n",
    "for group in ['ptosis']:\n",
    "    clean_group(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ON95B9Xu4LA5",
    "outputId": "78890022-69ee-4633-e7ba-1d50e68edffc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_info_df = pd.DataFrame(img_info_dic)\n",
    "img_info_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXuZ_5gcXWld"
   },
   "outputs": [],
   "source": [
    "if loading_success:\n",
    "    img_info_df = pd.concat([img_info_df, old_img_info_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "S--kT3QzXynw",
    "outputId": "a4ed5200-202f-444e-9f34-5b7e9f07e075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_info_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfLwJp8TXyrU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "DkdbUqbPXygW",
    "outputId": "0b965eed-abeb-4b58-caa5-e3f4cf896851"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_name</th>\n",
       "      <th>new_name</th>\n",
       "      <th>group</th>\n",
       "      <th>landmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02AC08319550-020116-374.33.JPG</td>\n",
       "      <td>ptosis_nvzpclozaoeidsnwdcpv.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>[(274, 257), (379, 167), (523, 163), (668, 250...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02AK13979406-060616-374.33.JPG</td>\n",
       "      <td>ptosis_eifbepvvxejylejtpgqb.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>[(300, 235), (427, 144), (592, 141), (742, 244...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    original_name  ...                                           landmark\n",
       "0  02AC08319550-020116-374.33.JPG  ...  [(274, 257), (379, 167), (523, 163), (668, 250...\n",
       "1  02AK13979406-060616-374.33.JPG  ...  [(300, 235), (427, 144), (592, 141), (742, 244...\n",
       "\n",
       "[2 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_info_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SekcMbS_dWCK"
   },
   "outputs": [],
   "source": [
    "# img_info_df.to_csv(file_dir + 'data/img_info_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RV0jV1msdWHH"
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(error_img).to_csv('error_img_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsZmkDYTeKpY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTJl3Vy2egSz"
   },
   "source": [
    "## Filter out the error images\n",
    "- **MANUAL LABLEING REQUIRED!**\n",
    "- Before this step, please check `error_img_df.csv` and other potential error images (e.g. images with very little file size). After verifying them, update the `error_img_df.csv` and proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSqhE2QweKnH"
   },
   "outputs": [],
   "source": [
    "img_info_df = pd.read_csv(file_dir + 'data/img_info_df.csv')\n",
    "error_img_df = pd.read_csv(file_dir + 'data/error_img_df.csv')\n",
    "error_img_names = set(error_img_df.new_name.values)\n",
    "\n",
    "# Construct the needed columns\n",
    "img_info_df['error'] = img_info_df.new_name.apply(lambda n: 1 if n in error_img_names else 0)\n",
    "img_info_df['filepath'] = img_info_df.apply(lambda s: s.group + '/' + s.new_name, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmkJ1mqBeKkV",
    "outputId": "19c8da2a-7fea-4d2e-e6c0-b6d57d6b3cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 709 images, 18 were not cleaned/cropped correctly.\n",
      "Out of 709 images, 257 were cleaned/cropped correctly AND had a label of \"normal eyes\".\n"
     ]
    }
   ],
   "source": [
    "num_error = img_info_df.query('error == 1').shape[0]\n",
    "num_normal = img_info_df.query('group == \"normal\" & error == \"0\"').shape[0]\n",
    "print('Out of', img_info_df.shape[0], 'images,', num_error, 'were not cleaned/cropped correctly.')\n",
    "print('Out of', img_info_df.shape[0], 'images,', num_normal, 'were cleaned/cropped correctly AND had a label of \"normal eyes\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "lGqPMUgLgFxe",
    "outputId": "556d7295-5b06-4b79-d4da-6dde61098e24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_name</th>\n",
       "      <th>new_name</th>\n",
       "      <th>group</th>\n",
       "      <th>error</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02AC08319550-020116-374.33.JPG</td>\n",
       "      <td>ptosis_nvzpclozaoeidsnwdcpv.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>0</td>\n",
       "      <td>ptosis/ptosis_nvzpclozaoeidsnwdcpv.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02AK13979406-060616-374.33.JPG</td>\n",
       "      <td>ptosis_eifbepvvxejylejtpgqb.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>0</td>\n",
       "      <td>ptosis/ptosis_eifbepvvxejylejtpgqb.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02AL30243827-090816-374.33.JPG</td>\n",
       "      <td>ptosis_saykhsfyqqtyolfzfshp.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>0</td>\n",
       "      <td>ptosis/ptosis_saykhsfyqqtyolfzfshp.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02AK12478616-031416-374.33.JPG</td>\n",
       "      <td>ptosis_eunkxhkcinmytgwlybrb.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>0</td>\n",
       "      <td>ptosis/ptosis_eunkxhkcinmytgwlybrb.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02AF30502849-062918-374.33.JPG</td>\n",
       "      <td>ptosis_lfmvjvxpyosmpzquvgup.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>0</td>\n",
       "      <td>ptosis/ptosis_lfmvjvxpyosmpzquvgup.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    original_name  ...                                filepath\n",
       "0  02AC08319550-020116-374.33.JPG  ...  ptosis/ptosis_nvzpclozaoeidsnwdcpv.JPG\n",
       "1  02AK13979406-060616-374.33.JPG  ...  ptosis/ptosis_eifbepvvxejylejtpgqb.JPG\n",
       "2  02AL30243827-090816-374.33.JPG  ...  ptosis/ptosis_saykhsfyqqtyolfzfshp.JPG\n",
       "3  02AK12478616-031416-374.33.JPG  ...  ptosis/ptosis_eunkxhkcinmytgwlybrb.JPG\n",
       "4  02AF30502849-062918-374.33.JPG  ...  ptosis/ptosis_lfmvjvxpyosmpzquvgup.JPG\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop un-necessary columns\n",
    "img_info_df = img_info_df.query('error == 0').drop(columns = ['landmark']).reset_index(drop = True)\n",
    "img_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "crSIinWFeKhe",
    "outputId": "d65f5cdd-0536-492a-8f83-f5ebbe9f5878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now saving the cleaning result summary sheet with: 691 images.\n"
     ]
    }
   ],
   "source": [
    "print('Now saving the cleaning result summary sheet with:', img_info_df.shape[0], 'images.')\n",
    "img_info_df.to_csv(file_dir + 'data/img_info_cleaned_no_error.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2GrJRecspeH"
   },
   "source": [
    "# 2. Pre-processing / Preparing Face Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "7P3qbMn7bXC5",
    "outputId": "db9b5a86-ea75-43aa-93fa-2a4ed8fb5635"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_name</th>\n",
       "      <th>new_name</th>\n",
       "      <th>group</th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02AC08319550-020116-374.33.JPG</td>\n",
       "      <td>ptosis_nvzpclozaoeidsnwdcpv.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>ptosis/ptosis_nvzpclozaoeidsnwdcpv.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02AK13979406-060616-374.33.JPG</td>\n",
       "      <td>ptosis_eifbepvvxejylejtpgqb.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>ptosis/ptosis_eifbepvvxejylejtpgqb.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02AL30243827-090816-374.33.JPG</td>\n",
       "      <td>ptosis_saykhsfyqqtyolfzfshp.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>ptosis/ptosis_saykhsfyqqtyolfzfshp.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02AK12478616-031416-374.33.JPG</td>\n",
       "      <td>ptosis_eunkxhkcinmytgwlybrb.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>ptosis/ptosis_eunkxhkcinmytgwlybrb.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02AM30491425-072718-374.33.JPG</td>\n",
       "      <td>ptosis_hcxzahrepngizofzprqp.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>ptosis/ptosis_hcxzahrepngizofzprqp.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    original_name  ... dataset\n",
       "0  02AC08319550-020116-374.33.JPG  ...     val\n",
       "1  02AK13979406-060616-374.33.JPG  ...   train\n",
       "2  02AL30243827-090816-374.33.JPG  ...    test\n",
       "3  02AK12478616-031416-374.33.JPG  ...   train\n",
       "4  02AM30491425-072718-374.33.JPG  ...   train\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_info_cleaned_no_error = pd.read_csv(file_dir + 'data/img_info_cleaned_no_error.csv')\n",
    "img_info_cleaned_no_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORLaxGv5u8wW"
   },
   "outputs": [],
   "source": [
    "file_dir = './drive/My Drive/oculoplastics_diagnosis/'\n",
    "img_dir = './drive/My Drive/oculoplastics_diagnosis/data/processed/'\n",
    "img_dir_normal = './drive/My Drive/oculoplastics_diagnosis/data/processed/normal/'\n",
    "img_dir_thyroid = './drive/My Drive/oculoplastics_diagnosis/data/processed/normal/thyroid_eye_disease/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TmdPQyDNGBE"
   },
   "source": [
    "## 2.1 Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ka6HUIXkHJAV"
   },
   "outputs": [],
   "source": [
    "# img_info_df.to_csv(file_dir + 'data/img_info_cleaned.csv', index = False)\n",
    "# img_info_cleaned = pd.read_csv(file_dir + 'data/img_info_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4fi_xKpNB97"
   },
   "outputs": [],
   "source": [
    "processed_img_dir = './drive/My Drive/oculoplastics_diagnosis/data/processed/'\n",
    "\n",
    "# Function to resize image\n",
    "def resize_to(desired_size, im_pth):\n",
    "    im = cv2.imread(im_pth, 0)\n",
    "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "\n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    # new_size should be in (width, height) format\n",
    "\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size // 2 - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w // 2, delta_w-(delta_w//2)\n",
    "\n",
    "    color = [0, 0, 0]\n",
    "    try:\n",
    "        new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
    "            value = color)\n",
    "        return new_im\n",
    "    except:\n",
    "        print('Error at:', im_pth)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EguYWoltlv2"
   },
   "outputs": [],
   "source": [
    "# display_one(resize_to(512, img_dir + 'normal/' + 'normal_rrkbifwnbxdvukfhmvgv.JPG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gl0phYluwjIC",
    "outputId": "2d162853-3c1d-44d3-8c5c-1601d2994289"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 690/690 [13:04<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "img_info_cleaned_no_error['resized_img'] = [resize_to(512, img_dir + fp) for fp in tqdm(img_info_cleaned_no_error.filepath)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4LqobiAhrLb"
   },
   "source": [
    "## 2.2 Assigning groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1_mVrK5HF7M"
   },
   "outputs": [],
   "source": [
    "def calc_label(group):\n",
    "    if group == 'normal':\n",
    "        return 0\n",
    "    if group == 'thyroid_eye_disease':\n",
    "        return 1\n",
    "    if group == 'ptosis':\n",
    "        return 2\n",
    "img_info_cleaned_no_error['label'] = img_info_cleaned_no_error.group.apply(calc_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8jj-AyIFW6N"
   },
   "source": [
    "## 2.3 Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zj9EsgtQh0JQ",
    "outputId": "4fe3eef5-adb6-442b-db31-ab36585a9af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images dropped because of NaN: 0\n"
     ]
    }
   ],
   "source": [
    "prev_shape = img_info_cleaned_no_error.shape[0]\n",
    "img_info_cleaned_no_error = img_info_cleaned_no_error.dropna().reset_index(drop = True)\n",
    "curr_shape = img_info_cleaned_no_error.shape[0]\n",
    "print('Number of images dropped because of NaN:', prev_shape - curr_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "Q_3GyXpWFYb4",
    "outputId": "e2deca77-34e9-40e3-c607-d0b031bd9c91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 690/690 [00:00<00:00, 14715.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split done, resulting in the following:\n",
      " Train: 338\n",
      " Val: 145\n",
      " Test: 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_name</th>\n",
       "      <th>new_name</th>\n",
       "      <th>group</th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>resized_img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02AC08319550-020116-374.33.JPG</td>\n",
       "      <td>ptosis_nvzpclozaoeidsnwdcpv.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>ptosis/ptosis_nvzpclozaoeidsnwdcpv.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>val</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02AK13979406-060616-374.33.JPG</td>\n",
       "      <td>ptosis_eifbepvvxejylejtpgqb.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>ptosis/ptosis_eifbepvvxejylejtpgqb.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    original_name  ...                                        resized_img\n",
       "0  02AC08319550-020116-374.33.JPG  ...  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "1  02AK13979406-060616-374.33.JPG  ...  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "\n",
       "[2 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = img_info_cleaned_no_error['resized_img'].values\n",
    "y = img_info_cleaned_no_error['label'].values\n",
    "\n",
    "all_idx = list(range(len(X)))\n",
    "X_train_idx, X_test_idx, y_train, y_test = train_test_split(all_idx, y, test_size = 0.3, random_state = 42)\n",
    "X_train_idx, X_val_idx, y_train, y_val = train_test_split([i for i in all_idx if i not in X_test_idx], y_train, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# print(len(X_train_idx), len(X_val_idx), len(X_test_idx))\n",
    "\n",
    "train_idx_dict = dict(zip(range(len(X_train_idx)), X_train_idx))\n",
    "val_idx_dict = dict(zip(range(len(X_val_idx)), X_val_idx))\n",
    "test_idx_dict = dict(zip(range(len(X_test_idx)), X_test_idx))\n",
    "\n",
    "X_train, X_val, X_test = X[X_train_idx], X[X_val_idx], X[X_test_idx]\n",
    "y_train, y_val, y_test = y[X_train_idx], y[X_val_idx], y[X_test_idx]\n",
    "# print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "img_info_cleaned_no_error['dataset'] = range(len(X))\n",
    "def calc_dataset(s):\n",
    "    if s in X_train_idx:\n",
    "        return 'train'\n",
    "    if s in X_val_idx:\n",
    "        return 'val'\n",
    "    if s in X_test_idx:\n",
    "        return 'test'\n",
    "img_info_cleaned_no_error.dataset = [calc_dataset(idx) for idx in tqdm (img_info_cleaned_no_error.dataset.values)]\n",
    "print('Split done, resulting in the following:')\n",
    "print(' Train:', len(y_train))\n",
    "print(' Val:', len(y_val))\n",
    "print(' Test:', len(y_test))\n",
    "img_info_cleaned_no_error.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IQb5IaZGb0w"
   },
   "source": [
    "## Save training info to local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-zqg65_dS8p"
   },
   "outputs": [],
   "source": [
    "f = open(data_dir + 'pickle/' + 'img_info_cleaned_no_error', 'wb')\n",
    "pickle.dump(img_info_cleaned_no_error, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnY2hj9QFfbR"
   },
   "outputs": [],
   "source": [
    "# img_info_cleaned_no_error = img_info_cleaned_no_error.drop(columns = ['resized_img'])\n",
    "img_info_cleaned_no_error.to_csv(file_dir + 'data/img_info_cleaned_no_error.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7WiOZUaFfe6"
   },
   "outputs": [],
   "source": [
    "f = open(data_dir + 'pickle/' + 'X_train', 'wb')\n",
    "pickle.dump(X_train, f)\n",
    "f.close()\n",
    "\n",
    "f = open(data_dir + 'pickle/' + 'X_val', 'wb')\n",
    "pickle.dump(X_val, f)\n",
    "f.close()\n",
    "\n",
    "f = open(data_dir + 'pickle/' + 'X_test', 'wb')\n",
    "pickle.dump(X_test, f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "f = open(data_dir + 'pickle/' + 'y_train', 'wb')\n",
    "pickle.dump(y_train, f)\n",
    "f.close()\n",
    "\n",
    "f = open(data_dir + 'pickle/' + 'y_val', 'wb')\n",
    "pickle.dump(y_val, f)\n",
    "f.close()\n",
    "\n",
    "f = open(data_dir + 'pickle/' + 'y_test', 'wb')\n",
    "pickle.dump(y_test, f)\n",
    "f.close()\n",
    "\n",
    "f = open(data_dir + 'pickle/' + 'train_idx_dict', 'wb')\n",
    "pickle.dump(train_idx_dict, f)\n",
    "f.close()\n",
    "\n",
    "f = open(data_dir + 'pickle/' + 'test_idx_dict', 'wb')\n",
    "pickle.dump(test_idx_dict, f)\n",
    "f.close()\n",
    "\n",
    "f = open(data_dir + 'pickle/' + 'val_idx_dict', 'wb')\n",
    "pickle.dump(val_idx_dict, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "LdyM3_zyddXk",
    "outputId": "9d5767e5-5c66-45ce-ba70-902aff7f8bbd"
   },
   "outputs": [],
   "source": [
    "# tmp = pickle.load(open(data_dir + 'pickle/' + 'img_info_cleaned_no_error', 'rb'))\n",
    "# tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ZLeG2kkdkLR",
    "outputId": "4365e474-c2e6-4f24-c7e2-92dde3e1a814"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tmp.resized_img.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLBFnRwuHRGo"
   },
   "source": [
    "# 3. Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6PlkPl3NJ8M"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y93QWm9G_Vn1"
   },
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "RBr3FxTCMx5O",
    "outputId": "b5e25f2c-5e3d-47ed-e959-dbc37a3d6584"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0cc426c48b1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# X_raw = img_info_cleaned['resized_img'].apply(lambda x: x.reshape(1, x.shape[0] * x.shape[1])[0]).values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_info_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resized_img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_info_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# X_raw = img_info_cleaned['resized_img'].apply(lambda x: x.reshape(1, x.shape[0] * x.shape[1])[0]).values\n",
    "X_raw = list(img_info_cleaned['resized_img'].apply(lambda x: list(x.flatten())).values)\n",
    "\n",
    "X = np.array(X_raw)\n",
    "y = img_info_cleaned['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sq0k47foB4gq"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVsnCIliLq3g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REUjdXuhLrUv"
   },
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8itjxl1Lqxk"
   },
   "outputs": [],
   "source": [
    "#importing all the required ML packages\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn import svm #support vector Machine\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from sklearn.naive_bayes import GaussianNB #Naive bayes\n",
    "\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6eajm2HwLwG5"
   },
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "acc_df = []\n",
    "for i in [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]:\n",
    "    model = LogisticRegression(C = i, max_iter = 1000) \n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_val)\n",
    "    acc_df.append({\n",
    "        'c': i,\n",
    "        'acc': (metrics.accuracy_score(prediction, y_val))\n",
    "    })\n",
    "best_c_log = pd.DataFrame(acc_df).sort_values(by = 'acc', ascending = False).iloc[0].c\n",
    "\n",
    "# Test best model\n",
    "model = LogisticRegression(C = best_c_log, max_iter = 1000) \n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_val)\n",
    "print('Best acc of LogReg:', (metrics.accuracy_score(prediction, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwMerxtXLwCm"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)\n",
    "print('Val acc for Logistic Regression is ', metrics.accuracy_score(prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sg4aUO-q_brL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vjmqc_ih_b8l"
   },
   "source": [
    "# 4. Neuro model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNxsm9NToG5U"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "import torch.optim as optim\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aF0g1oQf2NdG"
   },
   "outputs": [],
   "source": [
    "# config = {\n",
    "#     'model_idx': 1,\n",
    "#     'curr_label': 'label_ptosis',\n",
    "#     'data_pkl_dir': data_dir + 'pickle/' + 'img_info_cleaned_no_error',\n",
    "#     'class_num': 2,\n",
    "#     'chann1': 4,\n",
    "#     'chann2': 16,\n",
    "#     'chann3': 64,\n",
    "#     'mid_dim': 512,\n",
    "#     'dropout': 0.4,\n",
    "#     'batch_size': 20,\n",
    "#     'n_epochs': 2000,\n",
    "#     'from_checkpoint': 0\n",
    "# }\n",
    "# config['model_name'] = str(date.today()) + '-' + str(config['model_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "DQ0rKJgG6BRU",
    "outputId": "768e8140-0afe-45d5-a002-df7e12acfcbe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_name</th>\n",
       "      <th>new_name</th>\n",
       "      <th>group</th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>resized_img</th>\n",
       "      <th>label_ptosis</th>\n",
       "      <th>label_ted</th>\n",
       "      <th>img_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02AC08319550-020116-374.33.JPG</td>\n",
       "      <td>ptosis_nvzpclozaoeidsnwdcpv.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>ptosis/ptosis_nvzpclozaoeidsnwdcpv.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>val</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02AK13979406-060616-374.33.JPG</td>\n",
       "      <td>ptosis_eifbepvvxejylejtpgqb.JPG</td>\n",
       "      <td>ptosis</td>\n",
       "      <td>ptosis/ptosis_eifbepvvxejylejtpgqb.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    original_name  ... img_idx\n",
       "0  02AC08319550-020116-374.33.JPG  ...       0\n",
       "1  02AK13979406-060616-374.33.JPG  ...       1\n",
       "\n",
       "[2 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(data_dir + 'pickle/' + 'img_info_cleaned_no_error', 'rb')\n",
    "img_info_cleaned_no_error = pickle.load(f).reset_index(drop = True)\n",
    "f.close()\n",
    "# img_info_cleaned_no_error['img_idx'] = range(img_info_cleaned_no_error.shape[0])\n",
    "img_info_cleaned_no_error.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRs1jWz0raam"
   },
   "outputs": [],
   "source": [
    "# img_info_cleaned_no_error['label_ptosis'] = img_info_cleaned_no_error.group.apply(lambda g: 1 if g == 'ptosis' else 0)\n",
    "# img_info_cleaned_no_error['label_ted'] = img_info_cleaned_no_error.group.apply(lambda g: 1 if g == 'thyroid_eye_disease' else 0)\n",
    "pickle.dump(img_info_cleaned_no_error, open(data_dir + 'pickle/' + 'img_info_cleaned_no_error', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mK1CMZPradA",
    "outputId": "7eca6be5-efed-48d3-a716-0387c80dbae7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_info_cleaned_no_error.resized_img.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRPE9O2i9SrS"
   },
   "outputs": [],
   "source": [
    "# .astype(float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTgkkgIJ9Aw8"
   },
   "outputs": [],
   "source": [
    "# torch.tensor([i for i in img_info_cleaned_no_error.resized_img.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzkqIR4L5o5e"
   },
   "outputs": [],
   "source": [
    "# torch.tensor([torch.tensor(i.numpy()) for i in train_df.resized_img.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4GN-kebwdu-"
   },
   "source": [
    "## 4.1 Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dGccJ6rraiO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RP3Os4VJoBRD"
   },
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, config):\n",
    "        self.data_pkl_dir = config['data_pkl_dir']      \n",
    "        # config['original_size'] = self.data.resized_img.iloc[0].shape\n",
    "        self.original_size = config['original_size']\n",
    "        # self.model = DiagnoisisNet(config)\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.curr_label = config['curr_label']\n",
    "        self.class_num = config['class_num']\n",
    "        self.n_epochs = config['n_epochs']\n",
    "        self.from_checkpoint = config['from_checkpoint']\n",
    "        \n",
    "        self.model_name = config['model_name']\n",
    "\n",
    "        self.training_log = file_dir + 'models/training_log.txt'\n",
    "        self.testing_log = file_dir + 'models/testing_log.txt' \n",
    "\n",
    "        self.training_log_lst = []\n",
    "\n",
    "    def dataloader_prep(self, df, train = False):\n",
    "        data_set = TensorDataset(torch.tensor(df[self.curr_label].values), \n",
    "                                 torch.tensor([i for i in df.resized_img.values]), \n",
    "                                 torch.tensor(df.img_idx.values))\n",
    "        if train:\n",
    "            return DataLoader(data_set, sampler = RandomSampler(data_set), batch_size = self.batch_size)\n",
    "        else:\n",
    "            return DataLoader(data_set, sampler = SequentialSampler(data_set), batch_size = self.batch_size)\n",
    "\n",
    "    \n",
    "    def data_prep(self):\n",
    "        data_file = open(self.data_pkl_dir, 'rb')\n",
    "        data = pickle.load(data_file)\n",
    "        # data_file.close()\n",
    "        train_df = data.query('dataset == \"train\"')\n",
    "        val_df = data.query('dataset == \"val\"')\n",
    "        test_df = data.query('dataset == \"test\"')\n",
    "        # display(train_df)\n",
    "\n",
    "        # dataset_train = \n",
    "        # dataset_val = TensorDataset(torch.tensor(val_df.resized_img), \n",
    "        #                             torch.tensor(val_df[self.curr_label]), \n",
    "        #                             torch.tensor(val_df.img_idx))\n",
    "        # dataset_test = TensorDataset(torch.tensor(test_df.resized_img), \n",
    "        #                              torch.tensor(test_df[self.curr_label]), \n",
    "        #                              torch.tensor(test_df.img_idx))\n",
    "\n",
    "        train_dataloader = self.dataloader_prep(train_df, train = True)\n",
    "        val_dataloader = self.dataloader_prep(val_df)\n",
    "        test_dataloader = self.dataloader_prep(test_df)\n",
    "        return train_dataloader, val_dataloader, test_dataloader\n",
    "\n",
    "    def train(self):\n",
    "        # Data preparation\n",
    "        train_dataloader, val_dataloader, test_dataloader = self.data_prep()\n",
    "        \n",
    "        # create a complete CNN\n",
    "        model = DiagnoisisNet(config)\n",
    "        # print(model)\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if torch.cuda.is_available():\n",
    "            print('Using cuda!')\n",
    "            model.cuda()\n",
    "        # specify loss function (categorical cross-entropy)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # specify optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "        # optimizer = optim.SGD(model.parameters(), lr=0.00001)\n",
    "        # train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "        valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "        starting_epoch = self.from_checkpoint + 1\n",
    "        best_test_acc = 0\n",
    "        for epoch in tqdm(range(starting_epoch, starting_epoch + self.n_epochs)):\n",
    "\n",
    "            # keep track of training and validation loss\n",
    "            train_loss = 0.0\n",
    "            valid_loss = 0.0\n",
    "            \n",
    "            ###################\n",
    "            # train the model #\n",
    "            ###################\n",
    "            model.train()\n",
    "\n",
    "            # indices = torch.randperm(len(X_train), dtype = torch.long, device = 'cpu')\n",
    "            # train_dataloader = torch.utils.data.DataLoader(indices, batch_size = batch_size)\n",
    "            train_pred = []\n",
    "            train_label = []\n",
    "            train_scores = []\n",
    "            for batch in train_dataloader:\n",
    "                data, label, img_names = batch\n",
    "                # move tensors to GPU if CUDA is available\n",
    "                if train_on_gpu:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                # clear the gradients of all optimized variables\n",
    "                optimizer.zero_grad()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model(data)\n",
    "\n",
    "                # print(output.shape, target.shape)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, target)\n",
    "                # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                loss.backward()\n",
    "                # perform a single optimization step (parameter update)\n",
    "                optimizer.step()\n",
    "                # update training loss\n",
    "                train_loss += loss.item() * data.size(0)\n",
    "                output_scores = output.to('cpu').detach().numpy()\n",
    "                output = np.argmax(output_scores, axis = 1).flatten()\n",
    "                for o in output:\n",
    "                    train_pred.append(o)\n",
    "                for s in output_scores:\n",
    "                    train_scores.append(s)\n",
    "                for t in target:\n",
    "                    train_label.append(t)\n",
    "            train_acc = output_analysis(np.array(train_pred), np.array(train_label))['acc']\n",
    "\n",
    "            ######################    \n",
    "            # validate the model #\n",
    "            ######################\n",
    "            model.eval()\n",
    "            indices = list(range(len(X_val)))\n",
    "            test_dataloader = torch.utils.data.DataLoader(indices, batch_size = batch_size)\n",
    "            test_pred = []\n",
    "            test_label = []\n",
    "            test_scores = []\n",
    "            for batch in test_dataloader:\n",
    "                data, label, img_names = batch\n",
    "                # move tensors to GPU if CUDA is available\n",
    "                if train_on_gpu:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                with torch.no_grad():\n",
    "                    output = model(data)\n",
    "                # calculate the batch loss\n",
    "                \n",
    "                loss = criterion(output, target)\n",
    "                # update average validation loss \n",
    "                valid_loss += loss.item()*data.size(0)\n",
    "                # Update for acc\n",
    "                output_scores = output.to('cpu').detach().numpy()\n",
    "                output = np.argmax(output_scores, axis = 1).flatten()\n",
    "                for o in output:\n",
    "                    test_pred.append(o)\n",
    "                for s in output_scores:\n",
    "                    test_scores.append(s)\n",
    "                for t in target:\n",
    "                    test_label.append(t)\n",
    "            test_acc = output_analysis(np.array(test_pred), np.array(test_label))['acc']\n",
    "\n",
    "            # calculate average losses\n",
    "            train_loss = train_loss/len(X_train)\n",
    "            valid_loss = valid_loss/len(X_val)\n",
    "            \n",
    "            # if epoch % 10 == 0:\n",
    "            #     # print training/validation statistics \n",
    "            #     print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            #         epoch, train_loss, valid_loss))\n",
    "            #     print('Train acc:', train_acc, '; vali acc:', test_acc)\n",
    "            \n",
    "            # save model if validation loss has decreased\n",
    "            if test_acc > best_test_acc:\n",
    "                torch.save(model.state_dict(), 'tmp_model.pt')\n",
    "                best_test_acc = test_acc\n",
    "            tmp_summary_dict = {}\n",
    "            tmp_summary_dict['epoch'] = epoch\n",
    "            tmp_summary_dict['val_acc'] = test_acc\n",
    "            tmp_summary_dict['train_acc'] = train_acc\n",
    "            tmp_summary_dict['train_loss'] = train_loss\n",
    "            tmp_summary_dict['valid_loss'] = valid_loss\n",
    "            self.training_log_lst.append(tmp_summary_dict)\n",
    "        training_summary_df = pd.DataFrame(self.training_log_lst)\n",
    "\n",
    "        model = DiagnoisisNet(class_num = 3)\n",
    "        model.load_state_dict(torch.load('tmp_model.pt'))\n",
    "        test_acc = self.run_single_test(model, test_dataloader, return_prediction_dict = False)\n",
    "        torch.save(model.state_dict(), file_dir + 'models/model_' + self.model_name + '.pt')\n",
    "        return training_summary_df, test_acc\n",
    "\n",
    "    def run_single_test(self, model, dataloader, return_prediction_dict = True):\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "        print()\n",
    "        print(\" => Running Testing...\")\n",
    "\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "        test_label = []\n",
    "        test_pred = []\n",
    "        test_scores = []\n",
    "        all_prediction_dict = {}\n",
    "        first_batch = True\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in tqdm(test_dataloader):\n",
    "\n",
    "            data, label, img_names = batch\n",
    "             # move tensors to GPU if CUDA is available\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "    \n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            # Update for acc\n",
    "            output_scores = output.to('cpu').detach().numpy()\n",
    "            output = np.argmax(output_scores, axis = 1).flatten()\n",
    "            for o in output:\n",
    "                test_pred.append(o)\n",
    "            for s in output_scores:\n",
    "                test_scores.append(s)\n",
    "            for t in target:\n",
    "                test_label.append(t)\n",
    "\n",
    "            for i in range(len(img_names)):\n",
    "                all_prediction_dict[img_names[i]] = [output_scores[i], output[i]]\n",
    "        test_acc = output_analysis(np.array(test_pred), np.array(test_label))['acc']\n",
    "        \n",
    "        if return_prediction_dict:\n",
    "            return test_acc, all_prediction_dict\n",
    "        else:\n",
    "            return test_acc\n",
    "\n",
    "# define the CNN architecture\n",
    "class DiagnoisisNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(DiagnoisisNet, self).__init__()\n",
    "        self.original_w, self.original_h = config['original_size']\n",
    "        self.chann1 = config['chann1']\n",
    "        self.chann2 = config['chann2']\n",
    "        self.chann3 = config['chann3']\n",
    "        self.mid_dim = config['mid_dim']\n",
    "        self.class_num = config['class_num']\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, self.chann1, 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(self.chann1, self.chann2, 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(self.chann2, self.chann3, 3, padding = 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(self.chann3 * self.original_w * self.original_h, self.mid_dim)\n",
    "        self.fc2 = nn.Linear(self.mid_dim, self.class_num)\n",
    "        self.dropout = nn.Dropout(config['dropout'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, self.chann3 * self.original_w * self.original_h)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def output_analysis(pred, targets):\n",
    "    pred = np.array(pred)\n",
    "    targets = np.array([int(i.to('cpu')) for i in targets])\n",
    "    acc = accuracy_score(targets, pred)\n",
    "    return {\n",
    "        'acc': round(100 * acc, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "tuL8yDwi5UsR",
    "outputId": "cba601bf-fce6-4696-e30b-bea8e4a56c0a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-823b7c2385e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# T.curr_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "T = Trainer(config)\n",
    "T.train()\n",
    "# T.curr_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkJviFaYoBX2"
   },
   "outputs": [],
   "source": [
    "# # define the CNN architecture\n",
    "# class DiagnoisisNet(nn.Module):\n",
    "#     def __init__(self, class_num):\n",
    "#         super(DiagnoisisNet, self).__init__()\n",
    "#         # convolutional layer (sees 32x32x3 image tensor)\n",
    "#         self.conv1 = nn.Conv2d(1, 4, 3, padding = 1)\n",
    "#         # convolutional layer (sees 16x16x16 tensor)\n",
    "#         self.conv2 = nn.Conv2d(4, 16, 3, padding = 1)\n",
    "#         # # convolutional layer (sees 8x8x32 tensor)\n",
    "#         self.conv3 = nn.Conv2d(16, 64, 3, padding = 1)\n",
    "#         # max pooling layer\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "#         self.fc1 = nn.Linear(64 * 32 * 64, 512)\n",
    "\n",
    "#         self.fc2 = nn.Linear(512, class_num)\n",
    "#         # dropout layer (p=0.4)\n",
    "#         self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # add sequence of convolutional and max pooling layers\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = self.pool(F.relu(self.conv3(x)))\n",
    "#         print(x.shape)\n",
    "#         # flatten image input\n",
    "#         x = x.view(-1, 64 * 32 * 64)\n",
    "#         # add dropout layer\n",
    "#         x = self.dropout(x)\n",
    "#         # add 1st hidden layer, with relu activation function\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         # add dropout layer\n",
    "#         x = self.dropout(x)\n",
    "#         # add 2nd hidden layer, with relu activation function\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# def output_analysis(pred, targets):\n",
    "#     pred = np.array(pred)\n",
    "#     targets = np.array([int(i.to('cpu')) for i in targets])\n",
    "#     acc = accuracy_score(targets, pred)\n",
    "#     return {\n",
    "#         'acc': round(100 * acc, 2)\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLaoy8byL_Ae"
   },
   "source": [
    "## 4.1 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtHKWf-wEcTB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VZ4mxt9yvTI"
   },
   "source": [
    "- **Setting current label!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2-tncscypae"
   },
   "outputs": [],
   "source": [
    "# current_label = 'label_ptosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GEpOU4GqypdF"
   },
   "outputs": [],
   "source": [
    "# img_info_cleaned_no_error.resized_img.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlH3XfVXyphG"
   },
   "outputs": [],
   "source": [
    "# img_info_cleaned_no_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wn9CiTGhz7zm"
   },
   "outputs": [],
   "source": [
    "# sum(X_train[0] != img_info_cleaned_no_error.resized_img.values[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdD8bDWrvGc9"
   },
   "outputs": [],
   "source": [
    "# f = open(data_dir + 'pickle/' + 'X_train', 'rb')\n",
    "# X_train = pickle.load(f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4anJCWKOylsJ"
   },
   "outputs": [],
   "source": [
    "# type(X_train), len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UmQjbP6zqoZ"
   },
   "outputs": [],
   "source": [
    "# f = open(data_dir + 'pickle/' + 'train_idx_dict', 'rb')\n",
    "# train_idx_dict = pickle.load(f)\n",
    "# f.close()\n",
    "# # train_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4K0VG0oVJrK"
   },
   "outputs": [],
   "source": [
    "# f = open(data_dir + 'pickle/' + 'X_train', 'rb')\n",
    "# X_train = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "# f = open(data_dir + 'pickle/' + 'X_val', 'rb')\n",
    "# X_val = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "# f = open(data_dir + 'pickle/' + 'X_test', 'rb')\n",
    "# X_test = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "# f = open(data_dir + 'pickle/' + 'y_train', 'rb')\n",
    "# y_train = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "# f = open(data_dir + 'pickle/' + 'y_val', 'rb')\n",
    "# y_val = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "# f = open(data_dir + 'pickle/' + 'y_test', 'rb')\n",
    "# y_test = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "# f = open(data_dir + 'pickle/' + 'train_idx_dict', 'rb')\n",
    "# train_idx_dict = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "# f = open(data_dir + 'pickle/' + 'val_idx_dict', 'rb')\n",
    "# val_idx_dict = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "# f = open(data_dir + 'pickle/' + 'test_idx_dict', 'rb')\n",
    "# test_idx_dict = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "# print(X_train.shape, X_val.shape, X_test.shape)\n",
    "# print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWQ9Lx7pplZE"
   },
   "outputs": [],
   "source": [
    "# sum(y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkjO_oo2OK3C"
   },
   "outputs": [],
   "source": [
    "# img_info_cleaned_no_error = pd.read_csv(file_dir + 'data/img_info_cleaned_no_error.csv')\n",
    "# img_info_cleaned_no_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTM40huTW9Ob"
   },
   "outputs": [],
   "source": [
    "# img_info_cleaned_no_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vb1oud6eXIR4"
   },
   "outputs": [],
   "source": [
    "# X_train = torch.tensor(np.array([i for i in X_train]))\n",
    "# X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])).float()\n",
    "\n",
    "# X_val = torch.tensor(np.array([i for i in X_val]))\n",
    "# X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1], X_val.shape[2])).float()\n",
    "\n",
    "# X_test = torch.tensor(np.array([i for i in X_test]))\n",
    "# X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1], X_test.shape[2])).float()\n",
    "\n",
    "# y_train = torch.tensor(y_train)\n",
    "# y_val = torch.tensor(y_val)\n",
    "# y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7MA_P31mXKe"
   },
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvM_lgh8-6iD"
   },
   "outputs": [],
   "source": [
    "# # number of subprocesses to use for data loading\n",
    "# num_workers = 0\n",
    "# # how many samples per batch to load\n",
    "# batch_size = 20\n",
    "# # percentage of training set to use as validation\n",
    "# # valid_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDBZOb74wjES"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUNVGQDBQzKg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-q3dD-9-Fh7"
   },
   "outputs": [],
   "source": [
    "# # create a complete CNN\n",
    "# model = DiagnoisisNet(class_num = 3)\n",
    "# print(model)\n",
    "\n",
    "# # move tensors to GPU if CUDA is available\n",
    "# if torch.cuda.is_available():\n",
    "#     print('Using cuda!')\n",
    "#     model.cuda()\n",
    "\n",
    "# # specify loss function (categorical cross-entropy)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # specify optimizer\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "# # optimizer = optim.SGD(model.parameters(), lr=0.00001)\n",
    "\n",
    "# train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pm-o1behW2Ph"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dzwn1Z11BI5l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vlHpzF3i-Fqm"
   },
   "outputs": [],
   "source": [
    "# # number of epochs to train the model\n",
    "# n_epochs = 2000\n",
    "\n",
    "# valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "# best_test_acc = 0\n",
    "# for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "\n",
    "#     # keep track of training and validation loss\n",
    "#     train_loss = 0.0\n",
    "#     valid_loss = 0.0\n",
    "    \n",
    "#     ###################\n",
    "#     # train the model #\n",
    "#     ###################\n",
    "#     model.train()\n",
    "\n",
    "#     indices = torch.randperm(len(X_train), dtype = torch.long, device = 'cpu')\n",
    "#     train_dataloader = torch.utils.data.DataLoader(indices, batch_size = batch_size)\n",
    "#     train_pred = []\n",
    "#     train_label = []\n",
    "#     train_scores = []\n",
    "#     for idx in train_dataloader:\n",
    "#         data, target = X_train[idx], y_train[idx]\n",
    "#         # move tensors to GPU if CUDA is available\n",
    "#         if train_on_gpu:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "#         # clear the gradients of all optimized variables\n",
    "#         optimizer.zero_grad()\n",
    "#         # forward pass: compute predicted outputs by passing inputs to the model\n",
    "#         output = model(data)\n",
    "\n",
    "#         # print(output.shape, target.shape)\n",
    "#         # calculate the batch loss\n",
    "#         loss = criterion(output, target)\n",
    "#         # backward pass: compute gradient of the loss with respect to model parameters\n",
    "#         loss.backward()\n",
    "#         # perform a single optimization step (parameter update)\n",
    "#         optimizer.step()\n",
    "#         # update training loss\n",
    "#         train_loss += loss.item()*data.size(0)\n",
    "#         output_scores = output.to('cpu').detach().numpy()\n",
    "#         output = np.argmax(output_scores, axis = 1).flatten()\n",
    "#         for o in output:\n",
    "#             train_pred.append(o)\n",
    "#         for s in output_scores:\n",
    "#             train_scores.append(s)\n",
    "#         for t in target:\n",
    "#             train_label.append(t)\n",
    "#     train_acc = output_analysis(np.array(train_pred), np.array(train_label))['acc']\n",
    "\n",
    "#     ######################    \n",
    "#     # validate the model #\n",
    "#     ######################\n",
    "#     model.eval()\n",
    "#     indices = list(range(len(X_val)))\n",
    "#     test_dataloader = torch.utils.data.DataLoader(indices, batch_size = batch_size)\n",
    "#     test_pred = []\n",
    "#     test_label = []\n",
    "#     test_scores = []\n",
    "#     for idx in test_dataloader:\n",
    "#         data, target = X_val, y_val\n",
    "#         # move tensors to GPU if CUDA is available\n",
    "#         if train_on_gpu:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "#         # forward pass: compute predicted outputs by passing inputs to the model\n",
    "#         output = model(data)\n",
    "#         # calculate the batch loss\n",
    "        \n",
    "#         loss = criterion(output, target)\n",
    "#         # update average validation loss \n",
    "#         valid_loss += loss.item()*data.size(0)\n",
    "#         # Update for acc\n",
    "#         output_scores = output.to('cpu').detach().numpy()\n",
    "#         output = np.argmax(output_scores, axis = 1).flatten()\n",
    "#         for o in output:\n",
    "#             test_pred.append(o)\n",
    "#         for s in output_scores:\n",
    "#             test_scores.append(s)\n",
    "#         for t in target:\n",
    "#             test_label.append(t)\n",
    "#     test_acc = output_analysis(np.array(test_pred), np.array(test_label))['acc']\n",
    "\n",
    "#     # calculate average losses\n",
    "#     train_loss = train_loss/len(X_train)\n",
    "#     valid_loss = valid_loss/len(X_val)\n",
    "    \n",
    "#     # if epoch % 10 == 0:\n",
    "#     #     # print training/validation statistics \n",
    "#     #     print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "#     #         epoch, train_loss, valid_loss))\n",
    "#     #     print('Train acc:', train_acc, '; vali acc:', test_acc)\n",
    "    \n",
    "#     # save model if validation loss has decreased\n",
    "#     if test_acc > best_test_acc:\n",
    "#         torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "#         best_test_acc = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5j8NJE_-Fmr"
   },
   "outputs": [],
   "source": [
    "# model = DiagnoisisNet(class_num = 3)\n",
    "# model.load_state_dict(torch.load('model_cifar.pt'))\n",
    "# torch.save(model.state_dict(), file_dir + 'models/model_cifar.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irDXzwAp3jG1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEY9S6323jsP"
   },
   "source": [
    "- New trainer used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iy8xW3s53jJM"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_idx': 1,\n",
    "    'curr_label': 'label_ptosis',\n",
    "    'data_pkl_dir': data_dir + 'pickle/' + 'img_info_cleaned_no_error',\n",
    "    'class_num': 2,\n",
    "    'chann1': 4,\n",
    "    'chann2': 16,\n",
    "    'chann3': 64,\n",
    "    'mid_dim': 512,\n",
    "    'dropout': 0.4,\n",
    "    'batch_size': 20,\n",
    "    'n_epochs': 2000,\n",
    "    'from_checkpoint': 0,\n",
    "    'original_size': (256, 512)\n",
    "}\n",
    "config['model_name'] = str(date.today()) + '-' + str(config['model_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuJEFjHF3jK7"
   },
   "outputs": [],
   "source": [
    "T = Trainer(config)\n",
    "T.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "id": "-ywSU7303jNY",
    "outputId": "e8cf4cc2-19e5-4aeb-b2de-43466df50cb9"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a530101a21cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-91cfee55ae6d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Data preparation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# create a complete CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-91cfee55ae6d>\u001b[0m in \u001b[0;36mdata_prep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset == \"test\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresized_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mdataset_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresized_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdataset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresized_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_1OCdyvVv_c"
   },
   "source": [
    "## 4.2 Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XypoFAqSrtBP",
    "outputId": "b1444fff-c016-4eb6-f677-3cad03c23cf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiagnoisisNet(\n",
       "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=131072, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DiagnoisisNet(class_num = 3)\n",
    "model.load_state_dict(torch.load(file_dir + 'models/model_cifar.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2HLB8clVFNN",
    "outputId": "28188ddb-19fc-469f-990e-ca66405b72a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_train = model(X_train)\n",
    "train_scores = output_train.detach().numpy()\n",
    "output_train = np.argmax(train_scores, axis = 1).flatten()\n",
    "output_analysis(output_train, y_train)['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zuZDIie8t3Vw",
    "outputId": "09f09d29-de8d-4a51-cc2d-2a0c827aa687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.48"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_val = model(X_val)\n",
    "val_scores = output_val.detach().numpy()\n",
    "output_val = np.argmax(val_scores, axis = 1).flatten()\n",
    "output_analysis(output_val, y_val)['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfq-UHzxrtEd",
    "outputId": "fcd3647f-29d4-4130-f3ef-b7b9803d3e1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.4"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test = model(X_test)\n",
    "test_scores = output_test.detach().numpy()\n",
    "output_test = np.argmax(test_scores, axis = 1).flatten()\n",
    "output_analysis(output_test, y_test)['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uAiOG8WNSCq2",
    "outputId": "d0e1c3a9-90fd-4642-9440-31d999ff3ea5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 2, 1, 0, 2, 2,\n",
       "       0, 1, 0, 0, 0, 2, 1, 1, 2, 1, 1, 2, 1, 0, 0, 1, 0, 2, 0, 2, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 2, 0, 2, 1, 0, 1, 0, 1, 1, 2, 1, 0, 1, 0, 1,\n",
       "       0, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 1, 0, 2, 1, 1, 2, 1, 1, 0, 1, 2, 0, 0, 1, 2, 2, 1, 2, 1, 2,\n",
       "       2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1,\n",
       "       2, 0, 0, 2, 2, 1, 2, 2, 2, 2, 0, 1, 0, 0, 0, 1, 2, 1, 1, 1, 2, 2,\n",
       "       1, 2, 2, 0, 0, 1, 0, 0, 0, 2, 2, 0, 0, 1, 2, 0, 1, 0, 2, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 2, 0, 1, 0, 0, 2, 2, 0, 1, 2, 1, 1, 1, 0, 2, 2, 2,\n",
       "       2, 2, 0, 0, 0, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S35FPfkXQ1cu"
   },
   "outputs": [],
   "source": [
    "sftmax = nn.Softmax(dim = 1)\n",
    "\n",
    "train_scores = sftmax(torch.tensor(train_scores))\n",
    "val_scores = sftmax(torch.tensor(val_scores))\n",
    "test_scores = sftmax(torch.tensor(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "SzQxjjgvQ1fT",
    "outputId": "67669f02-177c-4a2c-8f5e-7ce3600fa6ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(max(train_scores[0])), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRMJegCGRhRS"
   },
   "outputs": [],
   "source": [
    "all_prediction = np.zeros(len(output_test) + len(output_train) + len(output_val))\n",
    "all_scores = np.zeros(len(all_prediction))\n",
    "for i in range(len(X_train)):\n",
    "    all_prediction[train_idx_dict[i]] = output_train[i]\n",
    "    all_scores[train_idx_dict[i]] = round(float(max(train_scores[i])), 2)\n",
    "for i in range(len(X_val)):\n",
    "    all_prediction[val_idx_dict[i]] = output_val[i]\n",
    "    all_scores[val_idx_dict[i]] = round(float(max(val_scores[i])), 2)\n",
    "for i in range(len(X_test)):\n",
    "    all_prediction[test_idx_dict[i]] = output_test[i]\n",
    "    all_scores[test_idx_dict[i]] = round(float(max(test_scores[i])), 2)\n",
    "\n",
    "img_info_cleaned['all_scores'] = all_scores\n",
    "img_info_cleaned['all_prediction'] = all_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFKSkv9JRhDM"
   },
   "outputs": [],
   "source": [
    "img_info_cleaned['correct'] = img_info_cleaned.apply(lambda s: 1 if s.all_prediction == s.label else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvnnJ36nV7Sp"
   },
   "outputs": [],
   "source": [
    "# img_info_cleaned.to_csv(file_dir + 'data/img_info_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqywoUQ7WAtp"
   },
   "source": [
    "## Score analysis\n",
    "- Statistical distribution\n",
    "- Statistical tests\n",
    "- Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "ognwIZSDpoVI",
    "outputId": "08969ef1-36b5-4a7d-c2ce-976024a737df"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f782332ff027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_info_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'data/img_info_cleaned.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimg_info_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "img_info_cleaned = pd.read_csv(file_dir + 'data/img_info_cleaned.csv')\n",
    "img_info_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "HMGbSjeEJ9z1",
    "outputId": "02339987-99bc-4fc6-dd06-0f4e4df6e17a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd8d064da90>"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(img_info_cleaned.query('dataset == \"test\" & correct == 0').all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "QF_mUquWJ985",
    "outputId": "3e017d11-cd74-47d2-c87b-eae2e4c3acaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd8d05c1198>"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(img_info_cleaned.query('dataset == \"test\" & correct == 1').all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "0LiUH5Z-J-Aa",
    "outputId": "348041c4-49f7-465c-b025-e28c362182f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd8d0580f60>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x = 'correct', y = 'all_scores', data = img_info_cleaned.query('dataset == \"test\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "INwiZC7UJ97P",
    "outputId": "1c21f990-c958-44d3-c4be-e28e5f546c20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ks_2sampResult(statistic=0.5396825396825397, pvalue=2.4950139819068795e-05)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "scipy.stats.ks_2samp(img_info_cleaned.query('dataset == \"test\" & correct == 0').all_scores, img_info_cleaned.query('dataset == \"test\" & correct == 1').all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXowoePVdaAp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7ez4eDtqDMJ"
   },
   "source": [
    "## Error case analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "HUAj_v1gdaFI",
    "outputId": "29a44cbf-c359-42e2-f901-f97ddf616771"
   },
   "outputs": [],
   "source": [
    "# img_info_cleaned.query('dataset == \"test\" & correct == 0').sort_values(by = 'all_scores', ascending = False)\\\n",
    "#     [['original_name', 'new_name', 'label', 'all_prediction', 'all_scores']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "dW8uYSOeqGGG",
    "outputId": "b31facd1-0f18-45d2-8735-3f5beaf2f440"
   },
   "outputs": [],
   "source": [
    "# high_score_failures = img_info_cleaned.query('dataset == \"test\" & correct == 0').sort_values(by = 'all_scores', ascending = False)\\\n",
    "#     [['original_name', 'new_name', 'label', 'all_prediction', 'all_scores']].query('all_scores > 0.8').reset_index(drop = True)\n",
    "# high_score_failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 841
    },
    "id": "C9F8QCUmqPCO",
    "outputId": "cd78de76-7bb2-4d6b-b5bb-3ba69e34b817"
   },
   "outputs": [],
   "source": [
    "# for i in range(high_score_failures.shape[0]):\n",
    "#     file_name = high_score_failures.new_name.iloc[i]\n",
    "#     file_path = '_'.join(file_name.split('_')[:-1])\n",
    "#     img_path = data_dir + 'processed/' + file_path + '/' + file_name\n",
    "#     # print(data_dir + file_path + '/' + file_name)\n",
    "#     img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "#     display_one(img, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fnbezI6qGcH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXALddBHqGZU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7O7LEZQiqGLL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "neoWwkNwqGDj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9L8U9Bxrs8o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGzU9bFZatrw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfRv0I4ZatnJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NsIi0IrMRsT"
   },
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBRzdsWp0uGN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-vd0dddK5NCb",
    "O2GrJRecspeH",
    "RLBFnRwuHRGo",
    "REUjdXuhLrUv",
    "x_1OCdyvVv_c",
    "gqywoUQ7WAtp"
   ],
   "name": "[Latest] facial_diagnosis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
